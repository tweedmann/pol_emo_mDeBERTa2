{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# torch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# pytorch libraries\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics import F1Score\n",
        "from torchmetrics.functional import accuracy, auroc #F1Score #f1\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "# transformers libraries\n",
        "from transformers import AutoTokenizer, DebertaV2Model, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-D2lGwBhRIAb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set working directory to the downloaded folder\n",
        "import os\n",
        "os.chdir('/path/to/your/directory')"
      ],
      "metadata": {
        "id": "Tb_-3h7-ROW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define function to apply mDeBERTa model\n",
        "LABEL_COLUMNS = ['anger_v2', 'fear_v2', 'disgust_v2', 'sadness_v2', 'joy_v2', 'enthusiasm_v2', 'pride_v2', 'hope_v2']\n",
        "BASE_MODEL_NAME = \"microsoft/mdeberta-v3-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
        "batch_size = 8\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "class CrowdCodedTagger(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
        "    super().__init__()\n",
        "    self.bert = DebertaV2Model.from_pretrained(BASE_MODEL_NAME, return_dict=True)\n",
        "    self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "    self.n_training_steps = n_training_steps\n",
        "    self.n_warmup_steps = n_warmup_steps\n",
        "    self.criterion = nn.BCELoss()\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels=None, token_type_ids=None):\n",
        "    output = self.bert(input_ids, attention_mask=attention_mask)\n",
        "    output = self.classifier(output.last_hidden_state[:, 0])\n",
        "    output = torch.sigmoid(output)\n",
        "    loss = 0\n",
        "    if labels is not None:\n",
        "        loss = self.criterion(output, labels)\n",
        "    return loss, output\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def training_epoch_end(self, outputs):\n",
        "\n",
        "    labels = []\n",
        "    predictions = []\n",
        "    for output in outputs:\n",
        "      for out_labels in output[\"labels\"].detach().cpu():\n",
        "        labels.append(out_labels)\n",
        "      for out_predictions in output[\"predictions\"].detach().cpu():\n",
        "        predictions.append(out_predictions)\n",
        "\n",
        "    labels = torch.stack(labels).int()\n",
        "    predictions = torch.stack(predictions)\n",
        "\n",
        "    for i, name in enumerate(LABEL_COLUMNS):\n",
        "      class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
        "      self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "\n",
        "    optimizer = AdamW(self.parameters(), lr=2e-5) #DEFINING LEARNING RATE\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "      optimizer,\n",
        "      num_warmup_steps=self.n_warmup_steps,\n",
        "      num_training_steps=self.n_training_steps\n",
        "    )\n",
        "\n",
        "    return dict(\n",
        "      optimizer=optimizer,\n",
        "      lr_scheduler=dict(\n",
        "        scheduler=scheduler,\n",
        "        interval='step'\n",
        "      )\n",
        "    )\n",
        "\n",
        "# Define function for inference\n",
        "def predict_labels(df):\n",
        "    input_text = df['sentence'].tolist()\n",
        "    num_inputs = len(input_text)\n",
        "    num_batches = (num_inputs - 1) // batch_size + 1\n",
        "    batched_input = [input_text[i * batch_size:(i + 1) * batch_size] for i in range(num_batches)]\n",
        "    batched_output = []\n",
        "\n",
        "    for i, batch in enumerate(tqdm.tqdm(batched_input)):\n",
        "        encoded_input = tokenizer(batch, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "        outputs = model(**encoded_input.to(device))\n",
        "\n",
        "        # Extract the decimal numbers from the tensor\n",
        "        tensor_values = outputs[1].tolist()\n",
        "        decimal_numbers = [[num for num in sublist] for sublist in tensor_values]\n",
        "\n",
        "        # Create Pandas DataFrame\n",
        "        output_df = pd.DataFrame(decimal_numbers, columns=LABEL_COLUMNS)\n",
        "\n",
        "        # Apply threshold function to DataFrame\n",
        "        threshold = 0.65\n",
        "        threshold_fn = lambda x: 1 if x >= threshold else 0\n",
        "        output_df = output_df.applymap(threshold_fn)\n",
        "\n",
        "        # Concatenate input DataFrame with output DataFrame\n",
        "        input_df = df.iloc[i * batch_size:(i + 1) * batch_size].reset_index(drop=True)\n",
        "        output_df = pd.concat([input_df, output_df], axis=1)\n",
        "\n",
        "        batched_output.append(output_df)\n",
        "\n",
        "\n",
        "    # Concatenate all batches into a single output DataFrame\n",
        "    output_df = pd.concat(batched_output, ignore_index=True)\n",
        "\n",
        "    return output_df"
      ],
      "metadata": {
        "id": "ZeN4YUW6RQLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#provide an input dataframe, for example by loading in a csv file\n",
        "#by default, the column in the dataframe including sentences to be classified should be called \"sentence\" (can be adjusted above)\n",
        "input_df = pd.read_csv(\"./example_data.csv\")\n",
        "input_df"
      ],
      "metadata": {
        "id": "6O1zqcMGRS9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# putting model into evaluation mode\n",
        "model = CrowdCodedTagger(n_classes=8)\n",
        "model.load_state_dict(torch.load(\"./model/pytorch_model.pt\"), strict = False)\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "tTKbA6P1XAHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply function to the input_df\n",
        "results = predict_labels(input_df)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "OjNK5uM9Rnud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save results as a csv file in the working directory\n",
        "result.to_csv('example_results.csv', index=False)"
      ],
      "metadata": {
        "id": "dxZOjE_2VXmc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}